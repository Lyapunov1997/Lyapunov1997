{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3QdGLfNs_57"
      },
      "source": [
        "# Neural Network & Deep learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHbaAswNs_58"
      },
      "source": [
        "## HW3 Q1 Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQh3ao23s_58"
      },
      "source": [
        "### Mohammad Hossein Saemi-810600215\n",
        "### Adrin gharibkhanian-810600235"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLTwC9-Ks_59"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3gFV3Kps_59"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms \n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAjTYS9a4bIk",
        "outputId": "0c3602f3-82b1-441a-fac2-721f0c578fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-upze58xs13"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),transforms.ToTensor()])\n",
        "DIR = \"/content/drive/MyDrive/EuroSAT/2750\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJVAsJmjFxM9"
      },
      "outputs": [],
      "source": [
        "data = ImageFolder(root=DIR,transform=transform)\n",
        "train_size = int(0.8 * len(data))\n",
        "test_size = len(data) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrGC4deBasxm"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    batch_size = 32,\n",
        "    num_workers = 2,\n",
        "    shuffle = True\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    batch_size = 32,\n",
        "    num_workers = 2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPxcjFXmbN35",
        "outputId": "3365835c-f999-4b34-b3b6-cbb8917ad368"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 64, 64]), torch.Size([32]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3ZpXZUzf5jE",
        "outputId": "f97d9b52-9cfd-4d5c-8c5b-6c0fb1955a24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['River',\n",
              " 'Residential',\n",
              " 'SeaLake',\n",
              " 'HerbaceousVegetation',\n",
              " 'Forest',\n",
              " 'Industrial',\n",
              " 'PermanentCrop',\n",
              " 'Pasture',\n",
              " 'AnnualCrop',\n",
              " 'Highway']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = os.listdir(DIR)\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "aT8BQMYMbXUP",
        "outputId": "77ab2380-8bd6-4175-f7f9-f1cf47b33607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image size: torch.Size([1, 64, 64])\n",
            "Label: 7\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img, label = train_features_batch[0], train_labels_batch[0]\n",
        "plt.imshow(img.permute(1, 2, 0), cmap='gray')\n",
        "plt.title(classes[label])\n",
        "plt.axis(\"Off\");\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UHHRp62IotY"
      },
      "outputs": [],
      "source": [
        "class VGG16(nn.Module):\n",
        "  def __init__(self,input,output):\n",
        "    super(VGG16,self).__init__()\n",
        "    self.CNN_block = nn.Sequential(\n",
        "         nn.Conv2d(in_channels = input,out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.Conv2d(in_channels = 32,out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
        "         nn.Conv2d(in_channels = 32,out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.Conv2d(in_channels = 64,out_channels = 64, kernel_size = 3, stride = 1, padding = 1), \n",
        "         nn.ReLU(),\n",
        "         nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
        "         nn.Conv2d(in_channels = 64,out_channels = 128, kernel_size = 3, stride = 1, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.Conv2d(in_channels = 128,out_channels = 128, kernel_size = 3, stride = 1, padding = 1), \n",
        "         nn.ReLU(),\n",
        "         nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
        "         nn.Conv2d(in_channels = 128,out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.Conv2d(in_channels = 256,out_channels = 256, kernel_size = 3, stride = 1, padding = 1), \n",
        "         nn.ReLU(),\n",
        "         nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
        "         nn.Conv2d(in_channels = 256,out_channels = 512, kernel_size = 3, stride = 1, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.Conv2d(in_channels = 512,out_channels = 512, kernel_size = 3, stride = 1, padding = 1), \n",
        "         nn.ReLU(),\n",
        "         nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "         nn.Flatten(start_dim=1),\n",
        "         nn.Linear(in_features= 512*2*2, out_features=4096),\n",
        "         nn.ReLU(),\n",
        "         nn.Dropout(0.5),  \n",
        "         nn.Linear(in_features= 4096, out_features=output),\n",
        "         nn.Softmax(dim=1) \n",
        "    )\n",
        "  def forward(self,x:torch.Tensor):\n",
        "    x = self.CNN_block(x)\n",
        "    #print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRawZpVMrOfr",
        "outputId": "2ed784f8-1d8f-463b-e1ad-e449992c5e57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (CNN_block): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): ReLU()\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU()\n",
              "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): ReLU()\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): ReLU()\n",
              "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=10, bias=True)\n",
              "    (5): Softmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = VGG16(input=1,output=10)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdJlURLgs_6A"
      },
      "outputs": [],
      "source": [
        "def train(model,\n",
        "          data_loader,\n",
        "          loss_fn,\n",
        "          optimizer,\n",
        "          accuracy_fn,\n",
        "          device):\n",
        "    \n",
        "    \n",
        "    model.to(device)\n",
        "    train_loss, train_acc, counter = 0, 0, 0\n",
        "    with tqdm(data_loader, desc =\"  train\") as train_tqdm:\n",
        "        for X, y in train_tqdm:\n",
        "            \n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            y_pred = model(X)\n",
        "\n",
        "            \n",
        "            loss = loss_fn(y_pred, y)\n",
        "            train_loss += loss\n",
        "            train_acc += accuracy_fn(true=y.cpu(),\n",
        "                                     pred=y_pred.cpu())\n",
        "            counter += 1\n",
        "            train_tqdm.set_postfix(train_acc=train_acc/counter, train_loss=train_loss.item()/counter, refresh=True)\n",
        "\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss /= len(data_loader)\n",
        "        train_acc /= len(data_loader)\n",
        "        \n",
        "    return train_loss.item(), train_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB59N_9as_6B"
      },
      "outputs": [],
      "source": [
        "def test(model,\n",
        "         data_loader,\n",
        "         loss_fn,\n",
        "         accuracy_fn,\n",
        "         device):\n",
        "    \n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "  \n",
        "    model.eval() \n",
        "    test_loss, test_acc, counter = 0, 0, 0\n",
        "    with tqdm(data_loader, desc =\"   test\") as test_tqdm:\n",
        "        for X, y in test_tqdm:\n",
        "          \n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "          \n",
        "            test_pred = model(X)\n",
        "            \n",
        "  \n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(true=y.cpu(),\n",
        "                                    pred=test_pred.cpu())\n",
        "            counter += 1\n",
        "            test_tqdm.set_postfix(test_acc=test_acc/counter, test_loss=test_loss.item()/counter, refresh=True)\n",
        "\n",
        "    \n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc  /= len(data_loader)\n",
        "            \n",
        "    return test_loss.item(), test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArEtCb11s_6B"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "def accuracy_fn(true, pred):\n",
        "    #pred = F.softmax(pred, dim = 1)\n",
        "    true = torch.zeros(pred.shape[0], pred.shape[1]).scatter_(1, true.unsqueeze(1), 1.)\n",
        "    acc = (true.argmax(-1) == pred.argmax(-1)).float().detach().numpy()\n",
        "    acc = float((100 * acc.sum()) / len(acc))\n",
        "    return round(acc, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUuWZr8Ps_6B",
        "outputId": "0a3686ca-133b-4c7a-a980-0de52cde502a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1/30 :\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  train: 100%|██████████| 675/675 [32:50<00:00,  2.92s/it, train_acc=10.9, train_loss=2.35]\n",
            "   test:  94%|█████████▍| 159/169 [07:44<00:29,  2.92s/it, test_acc=11.6, test_loss=2.35]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a582d1aaaaf4>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                                               \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                               )\n\u001b[0;32m---> 20\u001b[0;31m     test_loss, test_acc = test(data_loader=test_dataloader,\n\u001b[0m\u001b[1;32m     21\u001b[0m                                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e8607d6f8066>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, data_loader, loss_fn, accuracy_fn, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-930daf3b4ce9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNN_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.66 GiB already allocated; 16.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "train_epoch_loss = []\n",
        "train_epoch_accuracy = []\n",
        "test_epoch_loss = []\n",
        "test_epoch_accuracy = []\n",
        "\n",
        "train_time_start = timer()\n",
        "\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    print(\"EPOCH {}/{} :\".format(epoch +1, epochs))\n",
        "    train_loss, train_acc = train(data_loader=train_dataloader,\n",
        "                                              model=model, \n",
        "                                              loss_fn=loss_fn,\n",
        "                                              optimizer=optimizer,\n",
        "                                              accuracy_fn=accuracy_fn,\n",
        "                                              device=device\n",
        "                                              )\n",
        "    test_loss, test_acc = test(data_loader=test_dataloader,\n",
        "                                    model=model,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    accuracy_fn=accuracy_fn,\n",
        "                                    device=device\n",
        "                                    )\n",
        "    \n",
        "    train_epoch_loss.append(train_loss)\n",
        "    train_epoch_accuracy.append(train_acc)\n",
        "    test_epoch_loss.append(test_loss)\n",
        "    test_epoch_accuracy.append(test_acc)\n",
        "\n",
        "train_time_end = timer()\n",
        "total_time = train_time_end - train_time_start\n",
        "print(f\"\\n\\nTrain time: {total_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KgZI5ENP4pGE"
      },
      "outputs": [],
      "source": [
        "def accloss_plots(train_loss=train_epoch_loss, \n",
        "                  test_loss=test_epoch_loss, \n",
        "                  train_acc=train_epoch_accuracy, \n",
        "                  test_acc=test_epoch_accuracy):\n",
        "  \n",
        "    num_epochs = len(train_loss)\n",
        "    plt.figure(figsize=(13,5))\n",
        "    plt.subplot(121)\n",
        "    plt.plot(train_loss, 'r', label='Train')\n",
        "    plt.plot(test_loss , 'g', label='Test')\n",
        "    plt.xlabel('Epochs', fontsize=10, labelpad=8)\n",
        "    plt.title('Loss', fontsize=25, pad=15)\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    sns.despine()\n",
        "    plt.subplot(122)\n",
        "    plt.plot(train_acc, 'r', label='Train')\n",
        "    plt.plot(test_acc, 'g', label='Test')\n",
        "    plt.xlabel('Epochs', fontsize=10, labelpad=8)\n",
        "    plt.title('Accuracy', fontsize=25, pad=15)\n",
        "    plt.tight_layout(pad=3)\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    sns.despine()\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gCAhEkBA5EEj"
      },
      "outputs": [],
      "source": [
        "def make_predictions(model, data, device = device):\n",
        "    pred_probs = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    for sample in data:\n",
        "        # Prepare sample\n",
        "        sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
        "\n",
        "        # Forward pass (model outputs raw logit)\n",
        "        pred_logit = model(sample)\n",
        "\n",
        "        # Get prediction probability (logit -> prediction probability)\n",
        "        pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "        # Get pred_prob off GPU for further calculations\n",
        "        pred_probs.append(pred_prob.cpu())\n",
        "            \n",
        "    # Stack the pred_probs to turn list into a tensor\n",
        "    return torch.stack(pred_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f4hfe2P05F1I"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_dataset), k=9):\n",
        "    test_samples.append(sample)\n",
        "    test_labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T2tSmaMT5KEH"
      },
      "outputs": [],
      "source": [
        "# Make predictions on test samples with model\n",
        "pred_probs = make_predictions(model=model, data=test_samples)\n",
        "\n",
        "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
        "pred_classes = pred_probs.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Et-46BmC5Oh1"
      },
      "outputs": [],
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize=(9, 9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "    # Create a subplot\n",
        "    plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "    # Plot the target image\n",
        "    plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "    # Find the prediction label (in text form, e.g. \"Sandal\")\n",
        "    pred_label = test_dataset.classes[pred_classes[i]]\n",
        "\n",
        "    # Get the truth label (in text form, e.g. \"T-shirt\")\n",
        "    truth_label = test_dataset.classes[test_labels[i]] \n",
        "\n",
        "    # Create the title text of the plot\n",
        "    title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "    \n",
        "    # Check for equality and change title colour accordingly\n",
        "    if pred_label == truth_label:\n",
        "        plt.title(title_text, fontsize=10, c=\"g\") # green text if correct\n",
        "    else:\n",
        "        plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
        "    plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DerM6SwG5Svx"
      },
      "outputs": [],
      "source": [
        "y_preds = []\n",
        "model.eval()\n",
        "for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
        "    # Send data and targets to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    y_logit = model(X)\n",
        "\n",
        "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
        "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
        "\n",
        "    # Put predictions on CPU for evaluation\n",
        "    y_preds.append(y_pred.cpu())\n",
        "    \n",
        "# Concatenate list of predictions into a tensor\n",
        "y_pred_tensor = torch.cat(y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FUWqKSZA5YZV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "CM = confusion_matrix(y_true=test_dataset.targets,\n",
        "                      y_pred=y_pred_tensor)\n",
        "CM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w5khXulY5cww"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(CM, cmap='Blues', annot=True, cbar=False, fmt=\".0f\",\n",
        "            xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted Label', labelpad=20)\n",
        "plt.ylabel('True Label', labelpad=20)\n",
        "plt.title('Confusion Matrix', fontsize=30);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}